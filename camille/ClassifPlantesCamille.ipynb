{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de plantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports de base\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Classification sans features\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Mesures : accuracy , rappel, précision, f1 score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Skimage \n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.util import img_as_int\n",
    "\n",
    "# MultiThreading\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supprimer les warnings futurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = \"..\"+os.sep+\"data\"+os.sep+\"raw_data\"+ os.sep + \"metadata.csv\"\n",
    "df = pd.read_csv(file,sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combien de données (photos) on a pour chaque espèce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('species')['mediaid'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre total de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailleTotale = df.mediaid.unique().size\n",
    "print(tailleTotale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan des étapes à faire\n",
    "    Faire la somme cumulée des plantes : si y'a un gros pic => on a une espècee qui représente une grosse partie des données\n",
    "    \n",
    "    Est ce que les données sont bien balancées? \n",
    "    \n",
    "    Métrique: comment comparer les différents modèles? \n",
    "    Si données pas trop balancées: accuracy pas trop mal pour mesurer!\n",
    "    Moyenner par espèce: taux moyen pour chaque espèce\n",
    "    Mesurer le taux d'erreur : données non balancées (issues de l'app plantNet: attiré plus vers certaines plantes plutot que d'autres) \n",
    "    stratifySplit (split, trainset split) \n",
    "    \n",
    "    1) Prendre une baseline basique : \n",
    "        - Prendre un classifieur le plus naif possible et calculer son accuracy et on aura un accuracy de base \n",
    "        - permet de donner un sens aux chiffres \n",
    "        - Si moins bien que le truc très naif c'est qu'il y a un soucis\n",
    "    2) Mettre les images en entrée et de regarder ce qui sort d'un classifier linéaire. \n",
    "        a) Redimensionner : vectoriser \n",
    "        b) Balancer au classifier: tableau 3D \n",
    "    3) https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py\n",
    "    Celui ci retire les couleurs: importants pour les fleurs\n",
    "    Descripteur global sur image : si rotation alors problème , baisse de luminosité etc..\n",
    "    \n",
    "    Combiner les descripteurs : hog combiné à un descripteur de couleurs\n",
    "    \n",
    "    4) Bag-of-Visual-Words (BoVW) : Prend les descripteurs et en fait une représentation (marche plutot bien)\n",
    "    \n",
    "    5) Réseau neuronal : passer en entrée les images et lui va apprendre les features\n",
    "    Pytorch: CNN (exemples tutos) \n",
    "    MLP (Multi Layer perceptron : bcp plus rapide que le convutionnel)\n",
    "    Transfer learning : prendre un autre modele déja entrainé et le réutiliser : utile qd on a peu de données\n",
    "    Meilleur pour réseau neuronnaux de partir d'un modèle pré-enrtainé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification naïve: prédire toujours même classe (BaseLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est le classifieur le plus bas : si on a plu bas c'est qu'il y a un soucis qqs part.\n",
    "\n",
    "Papaver rhoeas L.                                          119 (à prédire)\n",
    "\n",
    "Calculer accuracy , f-measure, rappel\n",
    "\n",
    "Accuracy = nbre d'éléments corrects / nombre total\n",
    "Précision = nbre d'éléments corrects pour la classe / nbre prédit\n",
    "Rappel = nbre d'éléments correctement attribués à la classe / nbre de documents appartenant à la classe i (ici 119) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la prédiction qui prédit toujours la même classe (avec la classe qui a le plus de photo)\n",
    "def naivePredict(row):\n",
    "    return 30269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la prédiction naïve sur toutes les lignes du dataframe\n",
    "def predictionNaive(df):\n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        res = naivePredict(row)\n",
    "        if (res == row[\"classid\"]):\n",
    "            count = count + 1\n",
    "    #print(\"count : \", count)\n",
    "    acc = count / tailleTotale\n",
    "    prec = count / tailleTotale\n",
    "    rappel = count / 119\n",
    "    print(\"Accuracy : \", acc)\n",
    "    print(\"Précision : \", prec)\n",
    "    print(\"Rappel : \", rappel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction naive : \n",
    "predictionNaive(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification sans features (SVM, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réduire la taille de l'image car taille d'image trop grande (ne rentrera pas en mémoire) => descripteur de taille + petite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train data without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 6\n",
    "subset = 'train'\n",
    "\n",
    "folder = \"..\"+ os.sep + \"data\" + os.sep\n",
    "file =  subset + os.sep + subset + \".csv\"\n",
    "\n",
    "train_raw_df = pd.read_csv(folder + file,sep=\",\")\n",
    "train_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpath = folder + 'resized' + os.sep + subset + os.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_classifiers = []\n",
    "models_classifiers.append(('LinearSVC', LinearSVC(random_state=0, tol=1e-5)))\n",
    "models_classifiers.append(('SGDClassifier', SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)))\n",
    "models_classifiers.append(('LR', LogisticRegression()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgToVector(fname):\n",
    "    image = io.imread(loadpath + fname)\n",
    "    image = img_as_ubyte(image)\n",
    "    vector = image.reshape(100*100*3)\n",
    "    #vector = vector.flatten()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_image = Parallel(n_jobs=threads)(delayed(imgToVector)(str(i) + '.jpg') for i in train_raw_df['mediaid']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regarde comment c'est magique la liste d'images tout d'un coup et parallelise en plus  ! ;)\n",
    "liste_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_raw_df['classid']\n",
    "\n",
    "X_train = liste_image\n",
    "for name, clf in models_classifiers:\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Test Data\n",
    "subset = 'test'\n",
    "file =  subset + os.sep + subset + \".csv\"\n",
    "\n",
    "test_raw_df = pd.read_csv(folder + file,sep=\",\")\n",
    "test_raw_df.head()\n",
    "\n",
    "loadpath = folder + 'resized' + os.sep + subset + os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_image_test = Parallel(n_jobs=threads)(delayed(imgToVector)(str(i) + '.jpg') for i in test_raw_df['mediaid']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = liste_image_test\n",
    "y_true = test_raw_df['classid']\n",
    "\n",
    "y_predicts = []\n",
    "for name,clf in models_classifiers:\n",
    "    y_predicts.append(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_predict in y_predicts:\n",
    "    print(\"Accuracy: \" + str(accuracy_score(y_true, y_predict)))\n",
    "    print(\"Rappel: \" + str(recall_score(y_true, y_predict,average='micro')))\n",
    "    print(\"Precision: \" + str(precision_score(y_true, y_predict,average='micro')))\n",
    "    print(\"F-Measure: \" + str(precision_score(y_true, y_predict,average='micro')))\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification basique avec features HOG (SVM, LR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Regarder dans leonardo/resized (redimensionne l'image) et leonardo/hog (crée les features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data with features to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Data\n",
    "subset = 'train'\n",
    "\n",
    "folder = \"..\"+os.sep+\"data\"+os.sep\n",
    "file =  subset + os.sep + subset + \".csv\"\n",
    "\n",
    "train_raw_df = pd.read_csv(folder + file,sep=\",\")\n",
    "train_raw_df.head()\n",
    "\n",
    "hogpath = folder + 'resized' +os.sep+ subset + os.sep + subset + \"_hog.csv\"\n",
    "train_hog_df = pd.read_csv(hogpath,sep=\",\")\n",
    "train_hog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_classifiers = []\n",
    "models_classifiers.append(('LinearSVC', LinearSVC(random_state=0, tol=1e-5)))\n",
    "models_classifiers.append(('SGDClassifier', SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)))\n",
    "models_classifiers.append(('LR', LogisticRegression()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_hog_df\n",
    "y_train = train_raw_df['classid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,clf in models_classifiers:\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Test Data\n",
    "subset = 'test'\n",
    "file =  subset + os.sep + subset + \".csv\"\n",
    "\n",
    "test_raw_df = pd.read_csv(folder + file,sep=\",\")\n",
    "test_raw_df.head()\n",
    "\n",
    "hogpath = folder + 'resized' +os.sep + subset + os.sep + subset + \"_hog.csv\"\n",
    "test_hog_df = pd.read_csv(hogpath,sep=\",\")\n",
    "test_hog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_hog_df\n",
    "y_true = test_raw_df['classid']\n",
    "\n",
    "y_predicts = []\n",
    "for name,clf in models_classifiers:\n",
    "    y_predicts.append(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for y_predict in y_predicts:\n",
    "    print(\"Accuracy: \" + str(accuracy_score(y_true, y_predict)))\n",
    "    print(\"Rappel: \" + str(recall_score(y_true, y_predict,average='micro')))\n",
    "    print(\"Precision: \" + str(precision_score(y_true, y_predict,average='micro')))\n",
    "    print(\"F-Measure: \" + str(precision_score(y_true, y_predict,average='micro')))\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseaux de neurones"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuto : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "    1) Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
    "    2) Define a Convolutional Neural Network\n",
    "    3) Define a loss function\n",
    "    4) Train the network on the training data\n",
    "    5) Test the network on the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and normalizing "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If running on Windows and you get a BrokenPipeError, try setting\n",
    "the num_worker of torch.utils.data.DataLoader() to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observationid</th>\n",
       "      <th>mediaid</th>\n",
       "      <th>vote</th>\n",
       "      <th>content</th>\n",
       "      <th>classid</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>yearinclef</th>\n",
       "      <th>observationid2014</th>\n",
       "      <th>imageid2014</th>\n",
       "      <th>learntag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12510</td>\n",
       "      <td>1648</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>4369</td>\n",
       "      <td>Primulaceae</td>\n",
       "      <td>Primula</td>\n",
       "      <td>Primula veris L.</td>\n",
       "      <td>liliane roubaudi</td>\n",
       "      <td>2014-4-1</td>\n",
       "      <td>La Chapelle en Guinchay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PlantCLEF2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27147</td>\n",
       "      <td>111066</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>30162</td>\n",
       "      <td>Orchidaceae</td>\n",
       "      <td>Himantoglossum</td>\n",
       "      <td>Himantoglossum hircinum (L.) Spreng.</td>\n",
       "      <td>julien barataud</td>\n",
       "      <td>2006-6-14</td>\n",
       "      <td>Plévenon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ImageCLEF2013</td>\n",
       "      <td>14913.0</td>\n",
       "      <td>48553.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35639</td>\n",
       "      <td>17104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>6538</td>\n",
       "      <td>Orchidaceae</td>\n",
       "      <td>Anacamptis</td>\n",
       "      <td>Anacamptis morio (L.) R.M.Bateman, Pridgeon &amp; ...</td>\n",
       "      <td>marie portas</td>\n",
       "      <td>2012-3-19</td>\n",
       "      <td>Hyères</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ImageCLEF2013</td>\n",
       "      <td>6637.0</td>\n",
       "      <td>33907.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18747</td>\n",
       "      <td>30734</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>6415</td>\n",
       "      <td>Orchidaceae</td>\n",
       "      <td>Orchis</td>\n",
       "      <td>Orchis anthropophora (L.) All.</td>\n",
       "      <td>errol vela</td>\n",
       "      <td>2014-4-11</td>\n",
       "      <td>Sidi Aich, ALGERIE</td>\n",
       "      <td>36.6026</td>\n",
       "      <td>4.69448</td>\n",
       "      <td>PlantCLEF2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>26828</td>\n",
       "      <td>71634</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>5148</td>\n",
       "      <td>Salicaceae</td>\n",
       "      <td>Salix</td>\n",
       "      <td>Salix caprea L.</td>\n",
       "      <td>inge wullweber</td>\n",
       "      <td>2009-3-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PlantCLEF2014</td>\n",
       "      <td>2982.0</td>\n",
       "      <td>58691.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observationid  mediaid  vote content  classid       family           genus  \\\n",
       "0          12510     1648   4.0  Flower     4369  Primulaceae         Primula   \n",
       "1          27147   111066   3.0  Flower    30162  Orchidaceae  Himantoglossum   \n",
       "2          35639    17104   3.0  Flower     6538  Orchidaceae      Anacamptis   \n",
       "3          18747    30734   3.0  Flower     6415  Orchidaceae          Orchis   \n",
       "4          26828    71634   4.0  Flower     5148   Salicaceae           Salix   \n",
       "\n",
       "                                             species            author  \\\n",
       "0                                   Primula veris L.  liliane roubaudi   \n",
       "1               Himantoglossum hircinum (L.) Spreng.   julien barataud   \n",
       "2  Anacamptis morio (L.) R.M.Bateman, Pridgeon & ...      marie portas   \n",
       "3                     Orchis anthropophora (L.) All.        errol vela   \n",
       "4                                    Salix caprea L.    inge wullweber   \n",
       "\n",
       "        date                 location  latitude  longitude     yearinclef  \\\n",
       "0   2014-4-1  La Chapelle en Guinchay       NaN        NaN  PlantCLEF2015   \n",
       "1  2006-6-14                 Plévenon       NaN        NaN  ImageCLEF2013   \n",
       "2  2012-3-19                   Hyères       NaN        NaN  ImageCLEF2013   \n",
       "3  2014-4-11       Sidi Aich, ALGERIE   36.6026    4.69448  PlantCLEF2015   \n",
       "4  2009-3-11                      NaN       NaN        NaN  PlantCLEF2014   \n",
       "\n",
       "   observationid2014  imageid2014 learntag  \n",
       "0                NaN          NaN    Train  \n",
       "1            14913.0      48553.0    Train  \n",
       "2             6637.0      33907.0    Train  \n",
       "3                NaN          NaN    Train  \n",
       "4             2982.0      58691.0    Train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Train Data\n",
    "subset_train = 'train'\n",
    "\n",
    "folder = \"..\"+os.sep+\"data\"+os.sep\n",
    "file_train =  subset_train + os.sep + subset_train + \".csv\"\n",
    "\n",
    "train_raw_df = pd.read_csv(folder + file_train,sep=\",\")\n",
    "train_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observationid</th>\n",
       "      <th>mediaid</th>\n",
       "      <th>vote</th>\n",
       "      <th>content</th>\n",
       "      <th>classid</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>yearinclef</th>\n",
       "      <th>observationid2014</th>\n",
       "      <th>imageid2014</th>\n",
       "      <th>learntag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>36886</td>\n",
       "      <td>99451</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>8534</td>\n",
       "      <td>Ranunculaceae</td>\n",
       "      <td>Aconitum</td>\n",
       "      <td>Aconitum napellus L.</td>\n",
       "      <td>thierry pernot</td>\n",
       "      <td>1800-1-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PlantCLEF2014</td>\n",
       "      <td>208.0</td>\n",
       "      <td>22422.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31390</td>\n",
       "      <td>71276</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>2394</td>\n",
       "      <td>Cistaceae</td>\n",
       "      <td>Cistus</td>\n",
       "      <td>Cistus albidus L.</td>\n",
       "      <td>herve goeau</td>\n",
       "      <td>2013-6-5</td>\n",
       "      <td>Paris</td>\n",
       "      <td>48.84059</td>\n",
       "      <td>2.36158</td>\n",
       "      <td>PlantCLEF2014</td>\n",
       "      <td>2338.0</td>\n",
       "      <td>43988.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38327</td>\n",
       "      <td>61697</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>493</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Bellis</td>\n",
       "      <td>Bellis perennis L.</td>\n",
       "      <td>alexis joly</td>\n",
       "      <td>2014-3-8</td>\n",
       "      <td>Clermont-L'Hérault</td>\n",
       "      <td>43.64690</td>\n",
       "      <td>3.38675</td>\n",
       "      <td>PlantCLEF2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5105</td>\n",
       "      <td>34873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>661</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Cichorium</td>\n",
       "      <td>Cichorium intybus L.</td>\n",
       "      <td>liliane roubaudi</td>\n",
       "      <td>2013-9-13</td>\n",
       "      <td>Fleury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PlantCLEF2014</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>20340.0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18307</td>\n",
       "      <td>56154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flower</td>\n",
       "      <td>588</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Centaurea</td>\n",
       "      <td>Centaurea jacea L.</td>\n",
       "      <td>liliane roubaudi</td>\n",
       "      <td>2014-9-5</td>\n",
       "      <td>Vézins-de-Lévézou</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PlantCLEF2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observationid  mediaid  vote content  classid         family      genus  \\\n",
       "0          36886    99451   4.0  Flower     8534  Ranunculaceae   Aconitum   \n",
       "1          31390    71276   3.0  Flower     2394      Cistaceae     Cistus   \n",
       "2          38327    61697   4.0  Flower      493     Asteraceae     Bellis   \n",
       "3           5105    34873   4.0  Flower      661     Asteraceae  Cichorium   \n",
       "4          18307    56154   4.0  Flower      588     Asteraceae  Centaurea   \n",
       "\n",
       "                species            author       date            location  \\\n",
       "0  Aconitum napellus L.    thierry pernot   1800-1-1                 NaN   \n",
       "1     Cistus albidus L.       herve goeau   2013-6-5               Paris   \n",
       "2    Bellis perennis L.       alexis joly   2014-3-8  Clermont-L'Hérault   \n",
       "3  Cichorium intybus L.  liliane roubaudi  2013-9-13              Fleury   \n",
       "4    Centaurea jacea L.  liliane roubaudi   2014-9-5   Vézins-de-Lévézou   \n",
       "\n",
       "   latitude  longitude     yearinclef  observationid2014  imageid2014 learntag  \n",
       "0       NaN        NaN  PlantCLEF2014              208.0      22422.0    Train  \n",
       "1  48.84059    2.36158  PlantCLEF2014             2338.0      43988.0    Train  \n",
       "2  43.64690    3.38675  PlantCLEF2015                NaN          NaN    Train  \n",
       "3       NaN        NaN  PlantCLEF2014             3130.0      20340.0    Train  \n",
       "4       NaN        NaN  PlantCLEF2015                NaN          NaN    Train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Test Data\n",
    "subset_test = 'test'\n",
    "file_test =  subset_test + os.sep + subset_test + \".csv\"\n",
    "\n",
    "test_raw_df = pd.read_csv(folder + file_test,sep=\",\")\n",
    "test_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadpath\n",
    "loadpath_train = folder + os.sep + subset_train + os.sep\n",
    "loadpath_test = folder + os.sep + subset_test + os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgToVector2(loadpath, fname):\n",
    "    image = io.imread(loadpath + fname)\n",
    "    image = img_as_ubyte(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Parallel(n_jobs=threads)(delayed(imgToVector2)(loadpath_train, str(i) + '.jpg') for i in train_raw_df['mediaid']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Parallel(n_jobs=threads)(delayed(imgToVector2)(loadpath_test, str(i) + '.jpg') for i in test_raw_df['mediaid']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(train_raw_df['mediaid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0f02be0e7a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# get some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/M2/HMIN339M - Méthodes avancées de la science de données/ClassificationPlantes/env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/M2/HMIN339M - Méthodes avancées de la science de données/ClassificationPlantes/env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TRAIN MODEL\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
